{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dinamic Time Warping\n",
    "from dtaidistance import dtw\n",
    "from dtaidistance import dtw_visualisation as dtwvis\n",
    "from tslearn.metrics import cdist_dtw\n",
    "\n",
    "# Tensorflow / Keras\n",
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for assembling a Neural Network model\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, ReLU, LeakyReLU, Dropout # adding layers to the Neural Network model\n",
    "from tensorflow.keras.utils import plot_model # for plotting model diagram\n",
    "from tensorflow.keras.optimizers import Adam # for model optimization\n",
    "\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "import sklearn\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.preprocessing import MinMaxScaler # for scaling inputs used in the generator and discriminator\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import cv2 # for ingesting images\n",
    "print('OpenCV: %s' % cv2.__version__) # print version\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt # or data visualizationa\n",
    "print('matplotlib: %s' % matplotlib.__version__) # print version\n",
    "import graphviz # for showing model diagram\n",
    "print('graphviz: %s' % graphviz.__version__) # print version\n",
    "\n",
    "\n",
    "# Other utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Assign main directory to a variable\n",
    "# main_dir=os.path.dirname(sys.path[0])\n",
    "main_dir = './content'\n",
    "print(main_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generative Adversarial Network (DCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'CWRU_datasets/CWRU_preprocess_data/unbalanced_dataset/unbalanced_npy_by_labels'\n",
    "\n",
    "x_train = np.load(f'{data_path}/normaliced_data/x_train_norm_label1_20samples.npy')\n",
    "\n",
    "# 2D format\n",
    "n_img = 20 # time series\n",
    "data = x_train.reshape(n_img,40,40,1)\n",
    "\n",
    "# Show data shape\n",
    "print(\"Shape of data_lowres: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display10 = data.astype(np.float64)\n",
    "\n",
    "# Display 10 real images\n",
    "fig, axs = plt.subplots(2, 5, sharey=False, tight_layout=True, figsize=(10,5), facecolor='white')\n",
    "n=0\n",
    "for i in range(0,2):\n",
    "    for j in range(0,5):\n",
    "        axs[i,j].matshow(display10[n])\n",
    "        n=n+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_dim):\n",
    "    model = Sequential(name=\"Generator\") # Model\n",
    "\n",
    "    # Hidden Layer 1: Start with 5 x 5 image\n",
    "    n_nodes = 5 * 5 * 128 # number of nodes in the first hidden layer\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim, name='Generator-Hidden-Layer-1'))\n",
    "    model.add(Reshape((5, 5, 128), name='Generator-Hidden-Layer-Reshape-1'))\n",
    "\n",
    "    # Hidden Layer 2: Upsample to 10 x 10\n",
    "    model.add(Conv2DTranspose(filters=128, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-2'))\n",
    "    model.add(ReLU(name='Generator-Hidden-Layer-Activation-2'))\n",
    "\n",
    "    # Hidden Layer 3: Upsample to 20 x 20\n",
    "    model.add(Conv2DTranspose(filters=256, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-3'))\n",
    "    model.add(ReLU(name='Generator-Hidden-Layer-Activation-3'))\n",
    "\n",
    "    # Hidden Layer 4: Upsample to 40 x 40\n",
    "    model.add(Conv2DTranspose(filters=512, kernel_size=(4,4), strides=(2,2), padding='same', name='Generator-Hidden-Layer-4'))\n",
    "    model.add(ReLU(name='Generator-Hidden-Layer-Activation-4'))\n",
    "\n",
    "    # Output Layer (Note, we use 3 filters if we have 3 channels for a color image. Grayscale would have only 1 channel)\n",
    "    model.add(Conv2D(filters=1, kernel_size=(5,5), activation='sigmoid', padding='same', name='Generator-Output-Layer'))\n",
    "    return model\n",
    "\n",
    "# Instantiate\n",
    "latent_dim=100 # Our latent space has 100 dimensions. We can change it to any number\n",
    "gen_model = generator(latent_dim)\n",
    "\n",
    "# Show model summary and plot model diagram\n",
    "gen_model.summary()\n",
    "plot_model(gen_model, show_shapes=True, show_layer_names=True, dpi=60) #, to_file='generator_structure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(in_shape=(40,40,1)):\n",
    "    model = Sequential(name=\"Discriminator\") # Model\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    model.add(Conv2D(filters=64, kernel_size=(4,4), strides=(2, 2), padding='same', input_shape=in_shape, name='Discriminator-Hidden-Layer-1'))\n",
    "    model.add(LeakyReLU(negative_slope=0.2, name='Discriminator-Hidden-Layer-Activation-1'))\n",
    "\n",
    "    # Hidden Layer 2\n",
    "    model.add(Conv2D(filters=128, kernel_size=(4,4), strides=(2, 2), padding='same', input_shape=in_shape, name='Discriminator-Hidden-Layer-2'))\n",
    "    model.add(LeakyReLU(negative_slope=0.2, name='Discriminator-Hidden-Layer-Activation-2'))\n",
    "\n",
    "    # Hidden Layer 3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(4,4), strides=(2, 2), padding='same', input_shape=in_shape, name='Discriminator-Hidden-Layer-3'))\n",
    "    model.add(LeakyReLU(negative_slope=0.2, name='Discriminator-Hidden-Layer-Activation-3'))\n",
    "\n",
    "    # Flatten and Output Layers\n",
    "    model.add(Flatten(name='Discriminator-Flatten-Layer')) # Flatten the shape\n",
    "    model.add(Dropout(0.3, name='Discriminator-Flatten-Layer-Dropout')) # Randomly drop some connections for better generalization\n",
    "    model.add(Dense(1, activation='sigmoid', name='Discriminator-Output-Layer')) # Output Layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Instantiate\n",
    "dis_model = discriminator()\n",
    "\n",
    "# Show model summary and plot model diagram\n",
    "dis_model.summary()\n",
    "plot_model(dis_model, show_shapes=True, show_layer_names=True, dpi=60) #, to_file='discriminator_structure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator and Discriminator models into trainable GAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_gan(generator, discriminator):\n",
    "\n",
    "    # We don't want to train the weights of discriminator at this stage. Hence, make it not trainable\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Combine\n",
    "    model = Sequential(name=\"DCGAN\") # GAN Model\n",
    "    model.add(generator) # Add Generator\n",
    "    model.add(discriminator) # Add Disriminator\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# Instantiate\n",
    "gan_model = def_gan(gen_model, dis_model)\n",
    "\n",
    "# Show model summary and plot model diagram\n",
    "gan_model.summary()\n",
    "plot_model(gan_model, show_shapes=True, show_layer_names=True, dpi=60) #, to_file='dcgan_structure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to sample real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_samples(n, dataset):\n",
    "\n",
    "    # Samples of real data\n",
    "    X = dataset[np.random.choice(dataset.shape[0], n, replace=True), :]\n",
    "\n",
    "    # Class labels\n",
    "    y = np.ones((n, 1))\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate points in the latent space, which we will use as inputs for the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_vector(latent_dim, n):\n",
    "\n",
    "    # Generate points in the latent space\n",
    "    latent_input = np.random.randn(latent_dim * n)\n",
    "\n",
    "    # Reshape into a batch of inputs for the network\n",
    "    latent_input = latent_input.reshape(n, latent_dim)\n",
    "    return latent_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the generator to generate n artificial examples together with class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_samples(generator, latent_dim, n):\n",
    "\n",
    "    # Generate points in latent space\n",
    "    latent_output = latent_vector(latent_dim, n)\n",
    "\n",
    "    # Predict outputs (i.e., generate fake samples)\n",
    "    X = generator.predict(latent_output)\n",
    "\n",
    "    # Create class labels\n",
    "    y = np.zeros((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for model performance evaluation and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dinamyc Time Warping\n",
    "\n",
    "Dynamic time warping  is a way to compare two, usually temporal, sequences that do not perfectly sync up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_mean(x_train, generated_ts, referenceDTW =None):\n",
    "\n",
    "  # Generated times series DTW againts Original time series\n",
    "  #########################################################\n",
    "  means_array = []\n",
    "  for ts in generated_ts:\n",
    "    dtw_ts = cdist_dtw(ts,x_train)\n",
    "    dtw_ts_mean = np.mean(dtw_ts)\n",
    "    means_array.append(dtw_ts_mean)\n",
    "  \n",
    "  dtw_mean = np.mean(means_array)\n",
    "  \n",
    "  if referenceDTW != None:\n",
    "    print('\\n')\n",
    "    print('*** Reference DTW vs Actual DTW***')\n",
    "    print(f'Reference DTW mean: {referenceDTW}')\n",
    "    print(f'Actual DTW mean: {dtw_mean}')\n",
    "  \n",
    "  return dtw_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference DTW\n",
    "referenceDTW = dtw_mean(x_train, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator model accuracy and plot real vs. generated time series comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_discriminador_array = []\n",
    "loss_generador_array = []\n",
    "fake_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_summary(generator, discriminator, dataset, latent_dim, n=n_img):\n",
    "\n",
    "    # Get samples of the real data\n",
    "    x_real, y_real = real_samples(n, dataset)\n",
    "    # Evaluate the descriminator on real data\n",
    "    _, real_accuracy = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "\n",
    "    # Get fake (generated) samples\n",
    "    x_fake, y_fake = fake_samples(generator, latent_dim, n)\n",
    "    # Evaluate the descriminator on fake (generated) data\n",
    "    _, fake_accuracy = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "\n",
    "    # summarize discriminator performance\n",
    "    print('\\n')\n",
    "    print(\"*** Evaluation ***\")\n",
    "    print(\"Discriminator Accuracy on REAL images: \", real_accuracy)\n",
    "    print(\"Discriminator Accuracy on FAKE (generated) images: \", fake_accuracy)\n",
    "\n",
    "    # DTW verification\n",
    "    ##################\n",
    "    \n",
    "    # Reshape de las imagenes\n",
    "    x_fake_reshape = x_fake.reshape(n_img,1600)\n",
    "\n",
    "    # matriz de distancias\n",
    "    dtw_mean_value = dtw_mean(x_train, x_fake_reshape, referenceDTW)\n",
    "\n",
    "    # Plot Generate examples\n",
    "    ########################\n",
    "    fig, axs = plt.subplots(1,4, sharey=False, tight_layout=True, figsize=(8,3), facecolor='white')\n",
    "    k=0\n",
    "    plt.suptitle('Generated examples')\n",
    "    for i in range(4):\n",
    "            axs[i].matshow(x_fake[k])\n",
    "            k=k+1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train our DCGAN model (generator and discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs, n_batch, n_eval):\n",
    "\n",
    "    # Our batch to train the discriminator will consist of half real images and half fake (generated) images\n",
    "    half_batch = int(n_batch / 2)\n",
    "\n",
    "    # Manually enumare epochs\n",
    "    for i in range(n_epochs):\n",
    "\n",
    "    # Discriminator training\n",
    "        # Prep real samples\n",
    "        x_real, y_real = real_samples(half_batch, dataset)\n",
    "        # Prep fake (generated) samples\n",
    "        x_fake, y_fake = fake_samples(g_model, latent_dim, half_batch)\n",
    "\n",
    "        # Train the discriminator using real and fake samples\n",
    "        X, y = np.vstack((x_real, x_fake)), np.vstack((y_real, y_fake))\n",
    "        discriminator_loss, _ = d_model.train_on_batch(X, y)\n",
    "\n",
    "    # Generator training\n",
    "        # Get values from the latent space to be used as inputs for the generator\n",
    "        x_gan = latent_vector(latent_dim, n_batch)\n",
    "        # While we are generating fake samples,\n",
    "        # we want GAN generator model to create examples that resemble the real ones,\n",
    "        # hence we want to pass labels corresponding to real samples, i.e. y=1, not 0.\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "\n",
    "        # Train the generator via a composite GAN model\n",
    "        generator_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # Evaluate the model at every n_eval epochs\n",
    "        if (i) % n_eval == 0:\n",
    "            print('\\n')\n",
    "            print(\"Epoch number: \", i)\n",
    "            print(\"*** Training ***\")\n",
    "            print(\"Discriminator Loss: \", discriminator_loss)\n",
    "            loss_discriminador_array.append(discriminator_loss)\n",
    "\n",
    "            print(\"Generator Loss: \", generator_loss[0])\n",
    "            loss_generador_array.append(generator_loss[0])\n",
    "\n",
    "            performance_summary(g_model, d_model, dataset, latent_dim)\n",
    "\n",
    "            # # Guardar modelos\n",
    "            # print('Guardando modelos ...')\n",
    "            # gen_model.save(f'{save_path}/{label}/{label}_Generator_{i}epoch.h5')\n",
    "            # dis_model.save(f'{save_path}/{label}/{label}_Discriminator_{i}epoch.h5')\n",
    "            # gan_model.save(f'{save_path}/{label}/{label}_GAN_{i}epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def limpiar_log():\n",
    "    with open(join('./', 'DCGAN_training_logs.log'), 'w'):\n",
    "        pass\n",
    "    \n",
    "def imprimir_y_logear_mensaje(mensaje):\n",
    "    print(mensaje)\n",
    "\n",
    "    with open(join('./', 'DCGAN_training_logs.log'), 'a') as log_file:\n",
    "        log_file.write(mensaje + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DCGAN model\n",
    "# 1k epochs\n",
    "limpiar_log()\n",
    "mensaje_inicial = f'Comienzo del entrenamiento. {datetime.now()}'\n",
    "inicio = time.time()\n",
    "\n",
    "imprimir_y_logear_mensaje(mensaje_inicial)\n",
    "\n",
    "train(gen_model, dis_model, gan_model, data, latent_dim, n_epochs=1001, n_batch=32, n_eval=100)\n",
    "\n",
    "fin = time.time()\n",
    "tiempo_transcurrido = (fin - inicio) / 60\n",
    "imprimir_y_logear_mensaje(f'Tiempo total entrenado: {round(tiempo_transcurrido ,1)} minutos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Dobilas, S. (2022, octubre 15). Deep Convolutional GAN — How to Use a DCGAN to Generate Images in Python.   \n",
    "https://towardsdatascience.com/deep-convolutional-gan-how-to-use-a-dcgan-to-generate-images-in-python-b08afd4d124e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
